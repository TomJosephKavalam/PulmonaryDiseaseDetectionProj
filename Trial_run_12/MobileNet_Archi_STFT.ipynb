{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f9ab4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, GlobalAveragePooling2D, ReLU, Dense, DepthwiseConv2D, AveragePooling2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "677b221e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=np.load('y_train_temp.npy')\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6cf234e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 192, 753, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=np.load('X_train_temp.npy')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4e017a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=np.load('y_test_temp.npy')\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8cd7d749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 192, 753, 3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=np.load('X_test_temp.npy')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6fccd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array((X_train-np.min(X_train))/(np.max(X_train)-np.min(X_train)))\n",
    "X_test = np.array((X_test-np.min(X_test))/(np.max(X_test)-np.min(X_test)))\n",
    "X_train = X_train/np.std(X_train)\n",
    "X_test = X_test/np.std(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d83951a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 192, 753, 3) (146, 192, 753, 3) 219 146\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4, random_state=123)\n",
    "print(X_train.shape,  X_val.shape, len(y_train),  len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018ec50",
   "metadata": {},
   "source": [
    "<Font size = 6> <b> MobileNet Model </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7805ee89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 192, 753, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 96, 377, 32)       864       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 96, 377, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 96, 377, 32)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_4 (Depthwi  (None, 96, 377, 32)      288       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 96, 377, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 96, 377, 32)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 96, 377, 32)       1024      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 96, 377, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 96, 377, 32)       0         \n",
      "                                                                 \n",
      " depthwise_conv2d_5 (Depthwi  (None, 48, 189, 32)      288       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 48, 189, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 48, 189, 32)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 48, 189, 32)       1024      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 48, 189, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_14 (ReLU)             (None, 48, 189, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 24, 95, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 72960)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 291844    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 295,972\n",
      "Trainable params: 295,652\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def depth_block(x, strides):\n",
    "    x = DepthwiseConv2D(3,strides=strides,padding='same',  use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "def single_conv_block(x,filters):\n",
    "    x = Conv2D(filters, 1,use_bias=False)(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "def combo_layer(x,repetition, strides):\n",
    "    x = depth_block(x,strides)\n",
    "    filters=32\n",
    "    x = single_conv_block(x, filters)\n",
    "    return x\n",
    "def MobileNet(input_shape=(192, 753, 3),n_classes = 4):\n",
    "    input = Input (input_shape)\n",
    "    x = Conv2D(32,3,strides=(2,2),padding = 'same', use_bias=False) (input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = combo_layer(x,64, strides=(1,1))\n",
    "    #x = combo_layer(x,128,strides=(2,2))\n",
    "    #x = combo_layer(x,128,strides=(1,1))\n",
    "    #x = combo_layer(x,256,strides=(2,2))\n",
    "    #x = combo_layer(x,256,strides=(1,1))\n",
    "    #x = combo_layer(x,512,strides=(2,2))\n",
    "    #for _ in range(10):\n",
    "    #    x = combo_layer(x,512,strides=(1,1))\n",
    "    x = combo_layer(x,1024,strides=(2,2))\n",
    "    #x = combo_layer(x,1024,strides=(1,1))\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(x)\n",
    "    x=Flatten()(x)\n",
    "    output = Dense(n_classes,activation='softmax')(x)\n",
    "    model = Model(input, output)\n",
    "    return model\n",
    "n_classes = 4\n",
    "input_shape = (192, 753, 3)\n",
    "model = MobileNet(input_shape,n_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2219a3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(list(y_train).count(0),\n",
    "        list(y_train).count(1),\n",
    "        list(y_train).count(2),\n",
    "        list(y_train).count(3),\n",
    "        len(list(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "88ca3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, \n",
    "epsilon=1e-08, decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8adffce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78214286, 0.58870968, 1.95535714, 1.95535714])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "55452a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow_addons as tfa\n",
    "#from sklearn.metrics import f1_score\n",
    "\n",
    "coh_kap=tfa.metrics.CohenKappa(num_classes=4, sparse_labels=True)\n",
    "f1_score=tfa.metrics.F1Score(num_classes=4, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cd4e898b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45535714, 0.78214286, 0.78214286, 0.58870968, 0.78214286,\n",
       "       1.45535714, 0.58870968, 1.45535714, 1.95535714, 0.58870968,\n",
       "       0.78214286, 0.78214286, 0.78214286, 1.45535714, 0.58870968,\n",
       "       0.78214286, 0.78214286, 0.78214286, 0.58870968, 0.58870968,\n",
       "       0.78214286, 0.58870968, 0.58870968, 0.78214286, 1.45535714,\n",
       "       0.58870968, 0.78214286, 0.78214286, 0.58870968, 0.78214286,\n",
       "       0.78214286, 0.78214286, 0.78214286, 0.58870968, 1.95535714,\n",
       "       1.45535714, 0.78214286, 1.95535714, 0.58870968, 0.58870968,\n",
       "       0.58870968, 1.95535714, 0.58870968, 0.78214286, 0.58870968,\n",
       "       0.58870968, 0.78214286, 0.78214286, 0.58870968, 0.58870968,\n",
       "       0.58870968, 0.78214286, 0.78214286, 1.45535714, 0.58870968,\n",
       "       0.58870968, 0.78214286, 0.58870968, 0.78214286, 1.45535714,\n",
       "       0.78214286, 0.78214286, 0.78214286, 0.58870968, 0.78214286,\n",
       "       0.58870968, 1.45535714, 0.58870968, 0.58870968, 1.95535714,\n",
       "       0.78214286, 0.78214286, 0.78214286, 1.45535714, 0.58870968,\n",
       "       0.58870968, 1.95535714, 1.95535714, 0.58870968, 0.58870968,\n",
       "       0.78214286, 0.58870968, 1.45535714, 1.95535714, 0.58870968,\n",
       "       0.78214286, 0.58870968, 0.58870968, 0.78214286, 0.58870968,\n",
       "       1.45535714, 1.95535714, 0.78214286, 1.45535714, 0.78214286,\n",
       "       1.45535714, 0.58870968, 1.95535714, 1.95535714, 1.45535714,\n",
       "       1.95535714, 0.78214286, 0.58870968, 1.95535714, 0.58870968,\n",
       "       0.78214286, 1.45535714, 0.78214286, 0.58870968, 0.58870968,\n",
       "       0.58870968, 0.78214286, 0.78214286, 0.78214286, 0.58870968,\n",
       "       0.58870968, 0.58870968, 0.58870968, 1.95535714, 0.78214286,\n",
       "       0.58870968, 0.58870968, 0.58870968, 1.45535714, 1.95535714,\n",
       "       1.45535714, 1.95535714, 0.78214286, 0.58870968, 0.58870968,\n",
       "       0.78214286, 0.58870968, 0.58870968, 0.58870968, 1.45535714,\n",
       "       0.58870968, 0.58870968, 0.58870968, 1.45535714, 1.95535714,\n",
       "       0.58870968, 1.45535714, 1.45535714, 1.95535714, 0.78214286,\n",
       "       0.58870968, 0.78214286, 0.58870968, 0.78214286, 0.58870968,\n",
       "       0.58870968, 0.58870968, 0.58870968, 0.78214286, 0.58870968,\n",
       "       0.58870968, 0.58870968, 0.58870968, 0.58870968, 1.95535714,\n",
       "       0.58870968, 0.78214286, 0.58870968, 0.78214286, 1.95535714,\n",
       "       0.58870968, 1.45535714, 0.78214286, 0.58870968, 0.78214286,\n",
       "       0.58870968, 1.45535714, 0.58870968, 0.78214286, 0.58870968,\n",
       "       0.78214286, 0.78214286, 0.58870968, 1.45535714, 1.95535714,\n",
       "       0.58870968, 0.78214286, 0.58870968, 1.95535714, 1.95535714,\n",
       "       0.58870968, 0.58870968, 0.58870968, 1.95535714, 0.58870968,\n",
       "       1.45535714, 0.78214286, 0.58870968, 0.78214286, 0.78214286,\n",
       "       0.58870968, 0.58870968, 1.45535714, 0.78214286, 1.45535714,\n",
       "       0.78214286, 0.78214286, 1.95535714, 0.78214286, 0.58870968,\n",
       "       1.95535714, 0.78214286, 0.58870968, 0.58870968, 1.95535714,\n",
       "       1.95535714, 0.58870968, 0.78214286, 0.78214286, 0.58870968,\n",
       "       0.58870968, 0.78214286, 0.58870968, 0.78214286])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "\n",
    "sample_weight[y_train == 0] = class_weights[0]\n",
    "sample_weight[y_train == 1] = class_weights[1]\n",
    "sample_weight[y_train == 2] = class_weights[2]-.5\n",
    "sample_weight[y_train == 3] = class_weights[3]\n",
    "display(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8b8d1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=[coh_kap], sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "de99c95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.4034 - cohen_kappa: 0.4414 - val_loss: 1.4238 - val_cohen_kappa: 0.0000e+00\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 19s 3s/step - loss: 0.3669 - cohen_kappa: 0.8550 - val_loss: 1.4212 - val_cohen_kappa: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "md = model.fit(X_train, y_train, epochs=2, validation_data= (X_val, y_val), sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "adb44220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21846236, 0.26112014, 0.28438926, 0.23602818],\n",
       "       [0.22011256, 0.26369864, 0.2791176 , 0.2370712 ],\n",
       "       [0.22179306, 0.2655544 , 0.27929118, 0.23336141],\n",
       "       [0.21733013, 0.26383397, 0.28821322, 0.23062265],\n",
       "       [0.2152655 , 0.26206437, 0.2871233 , 0.23554683],\n",
       "       [0.21353523, 0.26349702, 0.287631  , 0.2353367 ],\n",
       "       [0.21612257, 0.26356688, 0.28780246, 0.23250806],\n",
       "       [0.22546421, 0.2611493 , 0.27855203, 0.23483448],\n",
       "       [0.21211907, 0.26629013, 0.2836595 , 0.23793124],\n",
       "       [0.221303  , 0.2573706 , 0.28212   , 0.23920636],\n",
       "       [0.22383851, 0.26366884, 0.28308904, 0.22940359],\n",
       "       [0.22417045, 0.26097503, 0.27883977, 0.23601477],\n",
       "       [0.22051372, 0.26072142, 0.293565  , 0.22519988],\n",
       "       [0.22572573, 0.26564738, 0.27922434, 0.22940257],\n",
       "       [0.22240314, 0.26742953, 0.27589035, 0.23427697],\n",
       "       [0.22528863, 0.2576853 , 0.28072184, 0.23630415],\n",
       "       [0.21931039, 0.26745543, 0.27982402, 0.23341018],\n",
       "       [0.2245558 , 0.2624866 , 0.277507  , 0.23545067],\n",
       "       [0.22164297, 0.25593117, 0.28338742, 0.23903841],\n",
       "       [0.2241618 , 0.26415557, 0.28134206, 0.23034059],\n",
       "       [0.21827339, 0.26668793, 0.28207588, 0.23296276],\n",
       "       [0.22513124, 0.25622   , 0.27996013, 0.23868862],\n",
       "       [0.22330523, 0.26341578, 0.2830948 , 0.23018424],\n",
       "       [0.22759718, 0.25981656, 0.2761343 , 0.23645197],\n",
       "       [0.22210248, 0.25400493, 0.28138727, 0.24250536],\n",
       "       [0.21863608, 0.26167884, 0.28059912, 0.23908599],\n",
       "       [0.22200471, 0.27090982, 0.27322704, 0.23385847],\n",
       "       [0.22499953, 0.27000776, 0.27576166, 0.22923101],\n",
       "       [0.2190168 , 0.2585627 , 0.28695738, 0.2354631 ],\n",
       "       [0.22213054, 0.26332563, 0.27814054, 0.23640323],\n",
       "       [0.22536637, 0.25913817, 0.2768389 , 0.2386566 ],\n",
       "       [0.22552086, 0.2673852 , 0.27507326, 0.23202063],\n",
       "       [0.22281136, 0.26376295, 0.28118622, 0.23223945],\n",
       "       [0.22516528, 0.2567523 , 0.28706864, 0.23101373],\n",
       "       [0.22052506, 0.26010635, 0.28040558, 0.23896296],\n",
       "       [0.22546326, 0.2628975 , 0.28224322, 0.22939602],\n",
       "       [0.21909527, 0.2655606 , 0.2863912 , 0.22895296],\n",
       "       [0.22166166, 0.25767508, 0.27880207, 0.24186116],\n",
       "       [0.22851904, 0.25628197, 0.27694657, 0.23825239],\n",
       "       [0.21867596, 0.26572767, 0.2813218 , 0.23427461],\n",
       "       [0.22359055, 0.25859138, 0.28307164, 0.23474652],\n",
       "       [0.22239102, 0.26223573, 0.2799105 , 0.23546264],\n",
       "       [0.22569054, 0.26425603, 0.2746449 , 0.23540848],\n",
       "       [0.2223377 , 0.25544766, 0.287257  , 0.23495762],\n",
       "       [0.21998328, 0.25690883, 0.28305137, 0.24005659],\n",
       "       [0.21830344, 0.25745276, 0.28320423, 0.24103953],\n",
       "       [0.2332742 , 0.2586003 , 0.2729148 , 0.23521069],\n",
       "       [0.22705977, 0.26415578, 0.28014773, 0.22863674],\n",
       "       [0.22153282, 0.2583172 , 0.28278807, 0.23736186],\n",
       "       [0.2292299 , 0.258682  , 0.28020686, 0.23188125],\n",
       "       [0.22803032, 0.25641513, 0.27871677, 0.23683776],\n",
       "       [0.22414564, 0.25273207, 0.27863672, 0.24448554],\n",
       "       [0.22381775, 0.25620207, 0.27974987, 0.24023032],\n",
       "       [0.2182821 , 0.25576407, 0.2812066 , 0.24474725],\n",
       "       [0.22114626, 0.2656935 , 0.27843374, 0.23472646],\n",
       "       [0.22369988, 0.2619485 , 0.28081813, 0.23353344],\n",
       "       [0.2240094 , 0.2585638 , 0.28071162, 0.23671524],\n",
       "       [0.2269608 , 0.26844826, 0.2854766 , 0.21911426],\n",
       "       [0.22787517, 0.26569638, 0.27470264, 0.23172577],\n",
       "       [0.2239723 , 0.26536494, 0.28828445, 0.22237833],\n",
       "       [0.22162469, 0.26534888, 0.27961263, 0.23341377],\n",
       "       [0.22092192, 0.26138258, 0.28224856, 0.23544699],\n",
       "       [0.2214071 , 0.26591235, 0.27967653, 0.23300403],\n",
       "       [0.22142754, 0.26419786, 0.27885213, 0.23552252],\n",
       "       [0.2242707 , 0.26019043, 0.27980593, 0.23573299],\n",
       "       [0.222502  , 0.2691005 , 0.27818525, 0.23021223],\n",
       "       [0.22177821, 0.2591537 , 0.28390393, 0.23516415],\n",
       "       [0.22605205, 0.26309842, 0.2881886 , 0.22266087],\n",
       "       [0.2259015 , 0.26774263, 0.27340573, 0.23295012],\n",
       "       [0.2208495 , 0.26265854, 0.2810546 , 0.23543741],\n",
       "       [0.22194418, 0.264137  , 0.27956042, 0.2343584 ],\n",
       "       [0.22613263, 0.27107006, 0.2847294 , 0.21806793],\n",
       "       [0.22726919, 0.27048904, 0.27428034, 0.22796142],\n",
       "       [0.22700453, 0.2627989 , 0.28298908, 0.22720747],\n",
       "       [0.22463757, 0.26022008, 0.28113016, 0.23401225],\n",
       "       [0.2177826 , 0.26158825, 0.28606808, 0.23456113],\n",
       "       [0.21806668, 0.26384515, 0.28354022, 0.2345479 ],\n",
       "       [0.22170407, 0.26241744, 0.2808003 , 0.23507829],\n",
       "       [0.22465804, 0.2674109 , 0.28142664, 0.2265044 ],\n",
       "       [0.21858567, 0.2614268 , 0.28787142, 0.2321161 ],\n",
       "       [0.22149864, 0.26528823, 0.2770975 , 0.2361157 ],\n",
       "       [0.2223639 , 0.2661288 , 0.27738053, 0.23412678],\n",
       "       [0.22376546, 0.2668543 , 0.2761085 , 0.23327172],\n",
       "       [0.22439961, 0.26726118, 0.27587092, 0.23246829],\n",
       "       [0.2259287 , 0.2576012 , 0.27823007, 0.23823997],\n",
       "       [0.22552414, 0.2599995 , 0.28247288, 0.23200347],\n",
       "       [0.21800758, 0.2608365 , 0.28655148, 0.23460443],\n",
       "       [0.223124  , 0.27231494, 0.28143612, 0.22312494],\n",
       "       [0.229344  , 0.26340634, 0.274974  , 0.23227574],\n",
       "       [0.23171325, 0.25687778, 0.2829133 , 0.22849561],\n",
       "       [0.22593164, 0.2603781 , 0.28351715, 0.23017307],\n",
       "       [0.22624516, 0.25403532, 0.27812633, 0.2415932 ],\n",
       "       [0.2184855 , 0.26456696, 0.2790237 , 0.23792379]], dtype=float32)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt=model.predict(X_test, verbose=0)\n",
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0c2ab280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  2\n",
      "0  2\n",
      "0  2\n",
      "1  2\n",
      "0  2\n",
      "2  2\n",
      "1  2\n",
      "2  2\n",
      "3  2\n",
      "1  2\n",
      "0  2\n",
      "0  2\n",
      "0  2\n",
      "2  2\n",
      "1  2\n",
      "0  2\n",
      "0  2\n",
      "0  2\n",
      "1  2\n",
      "1  2\n",
      "0  2\n",
      "1  2\n",
      "1  2\n",
      "0  2\n",
      "2  2\n",
      "1  2\n",
      "0  2\n",
      "0  2\n",
      "1  2\n",
      "0  2\n",
      "0  2\n",
      "0  2\n",
      "0  2\n",
      "1  2\n",
      "3  2\n",
      "2  2\n",
      "0  2\n",
      "3  2\n",
      "1  2\n",
      "1  2\n",
      "1  2\n",
      "3  2\n",
      "1  2\n",
      "0  2\n",
      "1  2\n",
      "1  2\n",
      "0  2\n",
      "0  2\n",
      "1  2\n",
      "1  2\n",
      "1  2\n",
      "0  2\n",
      "0  2\n",
      "2  2\n",
      "1  2\n",
      "1  2\n",
      "0  2\n",
      "1  2\n",
      "0  2\n",
      "2  2\n",
      "0  2\n",
      "0  2\n",
      "0  2\n",
      "1  2\n",
      "0  2\n",
      "1  2\n",
      "2  2\n",
      "1  2\n",
      "1  2\n",
      "3  2\n",
      "0  2\n",
      "0  2\n",
      "0  2\n",
      "2  2\n",
      "1  2\n",
      "1  2\n",
      "3  2\n",
      "3  2\n",
      "1  2\n",
      "1  2\n",
      "0  2\n",
      "1  2\n",
      "2  2\n",
      "3  2\n",
      "1  2\n",
      "0  2\n",
      "1  2\n",
      "1  2\n",
      "0  2\n",
      "1  2\n",
      "2  2\n",
      "3  2\n",
      "0  2\n"
     ]
    }
   ],
   "source": [
    "for i in range(yt.shape[0]):\n",
    "    print(str(y_train[i])+\"  \"+str(np.argmax(yt[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
