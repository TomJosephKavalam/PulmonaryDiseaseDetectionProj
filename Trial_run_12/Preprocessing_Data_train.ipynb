{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "377b220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import cv2\n",
    "import cmapy\n",
    "import nlpaug\n",
    "import nlpaug.augmenter.audio as naa\n",
    "from scipy.signal import butter, lfilter\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb969a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Recording_index</th>\n",
       "      <th>Chest_Location</th>\n",
       "      <th>Acquisition_Mode</th>\n",
       "      <th>Recording_equipment</th>\n",
       "      <th>Respiratory_cycles</th>\n",
       "      <th>Normal_cycles</th>\n",
       "      <th>Wheeze_cycles</th>\n",
       "      <th>Crackle_cycles</th>\n",
       "      <th>Both</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Train/Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b3</td>\n",
       "      <td>Al</td>\n",
       "      <td>mc</td>\n",
       "      <td>AKGC417L</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>107_2b3_Al_mc_AKGC417L.txt</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b3</td>\n",
       "      <td>Ar</td>\n",
       "      <td>mc</td>\n",
       "      <td>AKGC417L</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>107_2b3_Ar_mc_AKGC417L.txt</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b3</td>\n",
       "      <td>Ll</td>\n",
       "      <td>mc</td>\n",
       "      <td>AKGC417L</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>107_2b3_Ll_mc_AKGC417L.txt</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b3</td>\n",
       "      <td>Lr</td>\n",
       "      <td>mc</td>\n",
       "      <td>AKGC417L</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>107_2b3_Lr_mc_AKGC417L.txt</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Patient_ID  Disease Recording_index Chest_Location  \\\n",
       "0          13         107      NaN             2b3             Al   \n",
       "1          14         107      NaN             2b3             Ar   \n",
       "2          15         107      NaN             2b3             Ll   \n",
       "3          16         107      NaN             2b3             Lr   \n",
       "\n",
       "  Acquisition_Mode Recording_equipment  Respiratory_cycles  Normal_cycles  \\\n",
       "0               mc            AKGC417L                   8              1   \n",
       "1               mc            AKGC417L                   8              0   \n",
       "2               mc            AKGC417L                   8              0   \n",
       "3               mc            AKGC417L                   8              1   \n",
       "\n",
       "   Wheeze_cycles  Crackle_cycles  Both                    Filename Train/Test  \n",
       "0              0               7     0  107_2b3_Al_mc_AKGC417L.txt      train  \n",
       "1              0               1     7  107_2b3_Ar_mc_AKGC417L.txt      train  \n",
       "2              0               8     0  107_2b3_Ll_mc_AKGC417L.txt      train  \n",
       "3              0               7     0  107_2b3_Lr_mc_AKGC417L.txt      train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_train=pd.read_csv('Temp_train_audio.csv')\n",
    "audio_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ddb7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=4000\n",
    "fs=30000\n",
    "data_dir='AudioFiles2/'\n",
    "desired_length=8\n",
    "n_mels = 64\n",
    "nfft = 256\n",
    "hop = nfft//2\n",
    "f_max = 2000\n",
    "train_flag=1\n",
    "lowcut=3000\n",
    "highcut=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30f5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b,a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e654b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing into breath cycles\n",
    "def slice_data(start, end, raw_data, sample_rate):\n",
    "    max_ind = len(raw_data) \n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    y=butter_bandpass_filter(raw_data[start_ind: end_ind], lowcut, highcut, fs, order=5)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6752b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting label of each cycles\n",
    "def get_label(crackle, wheeze):\n",
    "    if crackle == 0 and wheeze == 0:\n",
    "        return 0\n",
    "    elif crackle == 1 and wheeze == 0:\n",
    "        return 1\n",
    "    elif crackle == 0 and wheeze == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0ac64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting breath cycle samples\n",
    "def get_sound_samples(file_name, data_dir, sample_rate):\n",
    "    sample_data = [file_name]\n",
    "    data, rate = librosa.load(os.path.join(data_dir, file_name+'.wav'), sr=sample_rate)\n",
    "    recording_annotations=pd.read_csv(data_dir+file_name+'.txt', sep='\\t', header=None)\n",
    "    \n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row[0]\n",
    "        end = row[1]\n",
    "        crackles = row[2]\n",
    "        wheezes = row[3]\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start,end, get_label(crackles, wheezes)))\n",
    "    return sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bbe05e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b3_Al_mc_AKGC417L going on 0 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:03,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b3_Ar_mc_AKGC417L going on 1 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:03,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b3_Ll_mc_AKGC417L going on 2 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:04,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b3_Lr_mc_AKGC417L going on 3 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:05,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b3_Pl_mc_AKGC417L going on 4 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:05,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b3_Pr_mc_AKGC417L going on 5 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:06,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b3_Tc_mc_AKGC417L going on 6 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:07,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b4_Al_mc_AKGC417L going on 7 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:07,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b4_Ar_mc_AKGC417L going on 8 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:08,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b4_Ll_mc_AKGC417L going on 9 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:09,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b4_Lr_mc_AKGC417L going on 10 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:09,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b4_Pl_mc_AKGC417L going on 11 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:10,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b4_Pr_mc_AKGC417L going on 12 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:11,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b4_Tc_mc_AKGC417L going on 13 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:11,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b5_Al_mc_AKGC417L going on 14 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:12,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b5_Ar_mc_AKGC417L going on 15 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:13,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b5_Ll_mc_AKGC417L going on 16 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:13,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b5_Lr_mc_AKGC417L going on 17 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:14,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b5_Pl_mc_AKGC417L going on 18 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:15,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b5_Pr_mc_AKGC417L going on 19 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:16,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_2b5_Tc_mc_AKGC417L going on 20 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:16,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_3p2_Al_mc_AKGC417L going on 21 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:17,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_3p2_Ar_mc_AKGC417L going on 22 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:18,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_3p2_Ll_mc_AKGC417L going on 23 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:18,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_3p2_Lr_mc_AKGC417L going on 24 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [00:19,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_3p2_Pl_mc_AKGC417L going on 25 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [00:20,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_3p2_Pr_mc_AKGC417L going on 26 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [00:20,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107_3p2_Tc_mc_AKGC417L going on 27 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [00:21,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108_1b1_Al_sc_Meditron going on 28 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:22,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110_1b1_Pr_sc_Meditron going on 29 out of 41\n",
      "110_1p1_Al_sc_Meditron going on 30 out of 41\n",
      "110_1p1_Ll_sc_Meditron going on 31 out of 41\n",
      "110_1p1_Lr_sc_Meditron going on 32 out of 41\n",
      "110_1p1_Pr_sc_Meditron going on 33 out of 41\n",
      "111_1b2_Tc_sc_Meditron going on 34 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [00:22,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111_1b3_Tc_sc_Meditron going on 35 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:23,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112_1b1_Ar_sc_Meditron going on 36 out of 41\n",
      "112_1b1_Lr_sc_Meditron going on 37 out of 41\n",
      "112_1p1_Ll_sc_Litt3200 going on 38 out of 41\n",
      "112_1p1_Pl_sc_Litt3200 going on 39 out of 41\n",
      "112_1p1_Pr_sc_Litt3200 going on 40 out of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#creating list of breath cycles with respective labels\n",
    "filenames=audio_train['Filename']\n",
    "filenames_with_labels=[]\n",
    "cycle_list = []\n",
    "classwise_cycle_list = [[], [], [], []]\n",
    "for idx, filename in tqdm(enumerate(filenames)):\n",
    "            file_name=filename.split('.')[0]\n",
    "            print(file_name+\" going on \"+str(idx)+\" out of \"+str(len(filenames)))\n",
    "            data = get_sound_samples(file_name, data_dir, sample_rate)\n",
    "            cycles_with_labels = [(d[0], d[3], file_name, cycle_idx, 0) for cycle_idx, d in enumerate(data[1:])]\n",
    "            cycle_list.extend(cycles_with_labels)\n",
    "            for cycle_idx, d in enumerate(cycles_with_labels):\n",
    "                filenames_with_labels.append(file_name+'_'+str(d[3])+'_'+str(d[1]))\n",
    "                classwise_cycle_list[d[1]].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "275490c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting and padding cycles\n",
    "def split_and_pad(original, desiredLength, sample_rate, types=0):\n",
    "\tif types==0:\n",
    "\t\treturn split_and_pad_old(original, desiredLength, sample_rate)\n",
    "\n",
    "\toutput_buffer_length = int(desiredLength*sample_rate)\n",
    "\tsoundclip = original[0].copy()\n",
    "\tn_samples = len(soundclip)\n",
    "\n",
    "\toutput = []\n",
    "\tif n_samples > output_buffer_length:\n",
    "\t\tframes = librosa.util.frame(soundclip, frame_length=output_buffer_length, hop_length=output_buffer_length//2, axis=0)\n",
    "\t\tfor i in range(frames.shape[0]):\n",
    "\t\t\toutput.append((frames[i], original[1], original[2], original[3], original[4], i, 0))\n",
    "\n",
    "\t\tlast_id = frames.shape[0]*(output_buffer_length//2)\n",
    "\t\tlast_sample = soundclip[last_id:]; pad_times = (output_buffer_length-len(last_sample))/len(last_sample)\n",
    "\t\tpadded = generate_padded_samples(soundclip, last_sample, output_buffer_length, sample_rate, types)\n",
    "\t\toutput.append((padded, original[1], original[2], original[3], original[4], i+1, pad_times))\n",
    "\n",
    "\telse:\n",
    "\t\tpadded = generate_padded_samples(soundclip, soundclip, output_buffer_length, sample_rate, types); pad_times = (output_buffer_length-len(soundclip))/len(soundclip)\n",
    "\t\toutput.append((padded, original[1], original[2], original[3], original[4], 0, pad_times))\n",
    "\n",
    "\treturn output\n",
    "\n",
    "\n",
    "def split_and_pad_old(original, desiredLength, sample_rate):\n",
    "    output_buffer_length = int(desiredLength * sample_rate)\n",
    "    soundclip = original[0].copy()\n",
    "    n_samples = len(soundclip)\n",
    "    total_length = n_samples / sample_rate #length of cycle in seconds\n",
    "    n_slices = int(math.ceil(total_length / desiredLength)) #get the minimum number of slices needed\n",
    "    samples_per_slice = n_samples // n_slices\n",
    "    src_start = 0 #Staring index of the samples to copy from the original buffer\n",
    "    output = [] #Holds the resultant slices\n",
    "    for i in range(n_slices):\n",
    "        src_end = min(src_start + samples_per_slice, n_samples)\n",
    "        length = src_end - src_start\n",
    "        copy = generate_padded_samples_old(soundclip[src_start:src_end], output_buffer_length)\n",
    "        output.append((copy, original[1], original[2], original[3], original[4], i))\n",
    "        src_start += length\n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_padded_samples(original, source, output_length, sample_rate, types):\n",
    "\tcopy = np.zeros(output_length, dtype=np.float32)\n",
    "\tsrc_length = len(source)\n",
    "\tleft = output_length-src_length # amount to be padded\n",
    "\t# pad front or back\n",
    "\tprob = random.random()\n",
    "\tif types == 1:\n",
    "\t\taug = original\n",
    "\telse:\n",
    "\t\taug = gen_augmented(original, sample_rate)\n",
    "\n",
    "\twhile len(aug) < left:\n",
    "\t\taug = np.concatenate([aug, aug])\n",
    "\n",
    "\tif prob < 0.5:\n",
    "\t\t#pad back\n",
    "\t\tcopy[left:] = source\n",
    "\t\tcopy[:left] = aug[len(aug)-left:]\n",
    "\telse:\n",
    "\t\t#pad front\n",
    "\t\tcopy[:src_length] = source[:]\n",
    "\t\tcopy[src_length:] = aug[:left]\n",
    "\n",
    "\treturn copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da7e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General augmentation augmentation\n",
    "def gen_augmented(original, sample_rate):\n",
    "\t# list of augmentors available from the nlpaug library\n",
    "\taugment_list = [\n",
    "\t#naa.CropAug(sampling_rate=sample_rate)\n",
    "\tnaa.NoiseAug(),\n",
    "\tnaa.SpeedAug(),\n",
    "\tnaa.LoudnessAug(factor=(0.5, 2)),\n",
    "\tnaa.VtlpAug(sampling_rate=sample_rate, zone=(0.0, 1.0)),\n",
    "\tnaa.PitchAug(sampling_rate=sample_rate, factor=(-1,3))\n",
    "\t]\n",
    "\t# sample augmentation randomly\n",
    "\taug_idx = random.randint(0, len(augment_list)-1)\n",
    "\taugmented_data = augment_list[aug_idx].augment(original)\n",
    "\treturn augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e42d824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 365\n",
      "1 out of 365\n",
      "2 out of 365\n",
      "3 out of 365\n",
      "4 out of 365\n",
      "5 out of 365\n",
      "6 out of 365\n",
      "7 out of 365\n",
      "8 out of 365\n",
      "9 out of 365\n",
      "10 out of 365\n",
      "11 out of 365\n",
      "12 out of 365\n",
      "13 out of 365\n",
      "14 out of 365\n",
      "15 out of 365\n",
      "16 out of 365\n",
      "17 out of 365\n",
      "18 out of 365\n",
      "19 out of 365\n",
      "20 out of 365\n",
      "21 out of 365\n",
      "22 out of 365\n",
      "23 out of 365\n",
      "24 out of 365\n",
      "25 out of 365\n",
      "26 out of 365\n",
      "27 out of 365\n",
      "28 out of 365\n",
      "29 out of 365\n",
      "30 out of 365\n",
      "31 out of 365\n",
      "32 out of 365\n",
      "33 out of 365\n",
      "34 out of 365\n",
      "35 out of 365\n",
      "36 out of 365\n",
      "37 out of 365\n",
      "38 out of 365\n",
      "39 out of 365\n",
      "40 out of 365\n",
      "41 out of 365\n",
      "42 out of 365\n",
      "43 out of 365\n",
      "44 out of 365\n",
      "45 out of 365\n",
      "46 out of 365\n",
      "47 out of 365\n",
      "48 out of 365\n",
      "49 out of 365\n",
      "50 out of 365\n",
      "51 out of 365\n",
      "52 out of 365\n",
      "53 out of 365\n",
      "54 out of 365\n",
      "55 out of 365\n",
      "56 out of 365\n",
      "57 out of 365\n",
      "58 out of 365\n",
      "59 out of 365\n",
      "60 out of 365\n",
      "61 out of 365\n",
      "62 out of 365\n",
      "63 out of 365\n",
      "64 out of 365\n",
      "65 out of 365\n",
      "66 out of 365\n",
      "67 out of 365\n",
      "68 out of 365\n",
      "69 out of 365\n",
      "70 out of 365\n",
      "71 out of 365\n",
      "72 out of 365\n",
      "73 out of 365\n",
      "74 out of 365\n",
      "75 out of 365\n",
      "76 out of 365\n",
      "77 out of 365\n",
      "78 out of 365\n",
      "79 out of 365\n",
      "80 out of 365\n",
      "81 out of 365\n",
      "82 out of 365\n",
      "83 out of 365\n",
      "84 out of 365\n",
      "85 out of 365\n",
      "86 out of 365\n",
      "87 out of 365\n",
      "88 out of 365\n",
      "89 out of 365\n",
      "90 out of 365\n",
      "91 out of 365\n",
      "92 out of 365\n",
      "93 out of 365\n",
      "94 out of 365\n",
      "95 out of 365\n",
      "96 out of 365\n",
      "97 out of 365\n",
      "98 out of 365\n",
      "99 out of 365\n",
      "100 out of 365\n",
      "101 out of 365\n",
      "102 out of 365\n",
      "103 out of 365\n",
      "104 out of 365\n",
      "105 out of 365\n",
      "106 out of 365\n",
      "107 out of 365\n",
      "108 out of 365\n",
      "109 out of 365\n",
      "110 out of 365\n",
      "111 out of 365\n",
      "112 out of 365\n",
      "113 out of 365\n",
      "114 out of 365\n",
      "115 out of 365\n",
      "116 out of 365\n",
      "117 out of 365\n",
      "118 out of 365\n",
      "119 out of 365\n",
      "120 out of 365\n",
      "121 out of 365\n",
      "122 out of 365\n",
      "123 out of 365\n",
      "124 out of 365\n",
      "125 out of 365\n",
      "126 out of 365\n",
      "127 out of 365\n",
      "128 out of 365\n",
      "129 out of 365\n",
      "130 out of 365\n",
      "131 out of 365\n",
      "132 out of 365\n",
      "133 out of 365\n",
      "134 out of 365\n",
      "135 out of 365\n",
      "136 out of 365\n",
      "137 out of 365\n",
      "138 out of 365\n",
      "139 out of 365\n",
      "140 out of 365\n",
      "141 out of 365\n",
      "142 out of 365\n",
      "143 out of 365\n",
      "144 out of 365\n",
      "145 out of 365\n",
      "146 out of 365\n",
      "147 out of 365\n",
      "148 out of 365\n",
      "149 out of 365\n",
      "150 out of 365\n",
      "151 out of 365\n",
      "152 out of 365\n",
      "153 out of 365\n",
      "154 out of 365\n",
      "155 out of 365\n",
      "156 out of 365\n",
      "157 out of 365\n",
      "158 out of 365\n",
      "159 out of 365\n",
      "160 out of 365\n",
      "161 out of 365\n",
      "162 out of 365\n",
      "163 out of 365\n",
      "164 out of 365\n",
      "165 out of 365\n",
      "166 out of 365\n",
      "167 out of 365\n",
      "168 out of 365\n",
      "169 out of 365\n",
      "170 out of 365\n",
      "171 out of 365\n",
      "172 out of 365\n",
      "173 out of 365\n",
      "174 out of 365\n",
      "175 out of 365\n",
      "176 out of 365\n",
      "177 out of 365\n",
      "178 out of 365\n",
      "179 out of 365\n",
      "180 out of 365\n",
      "181 out of 365\n",
      "182 out of 365\n",
      "183 out of 365\n",
      "184 out of 365\n",
      "185 out of 365\n",
      "186 out of 365\n",
      "187 out of 365\n",
      "188 out of 365\n",
      "189 out of 365\n",
      "190 out of 365\n",
      "191 out of 365\n",
      "192 out of 365\n",
      "193 out of 365\n",
      "194 out of 365\n",
      "195 out of 365\n",
      "196 out of 365\n",
      "197 out of 365\n",
      "198 out of 365\n",
      "199 out of 365\n",
      "200 out of 365\n",
      "201 out of 365\n",
      "202 out of 365\n",
      "203 out of 365\n",
      "204 out of 365\n",
      "205 out of 365\n",
      "206 out of 365\n",
      "207 out of 365\n",
      "208 out of 365\n",
      "209 out of 365\n",
      "210 out of 365\n",
      "211 out of 365\n",
      "212 out of 365\n",
      "213 out of 365\n",
      "214 out of 365\n",
      "215 out of 365\n",
      "216 out of 365\n",
      "217 out of 365\n",
      "218 out of 365\n",
      "219 out of 365\n",
      "220 out of 365\n",
      "221 out of 365\n",
      "222 out of 365\n",
      "223 out of 365\n",
      "224 out of 365\n",
      "225 out of 365\n",
      "226 out of 365\n",
      "227 out of 365\n",
      "228 out of 365\n",
      "229 out of 365\n",
      "230 out of 365\n",
      "231 out of 365\n",
      "232 out of 365\n",
      "233 out of 365\n",
      "234 out of 365\n",
      "235 out of 365\n",
      "236 out of 365\n",
      "237 out of 365\n",
      "238 out of 365\n",
      "239 out of 365\n",
      "240 out of 365\n",
      "241 out of 365\n",
      "242 out of 365\n",
      "243 out of 365\n",
      "244 out of 365\n",
      "245 out of 365\n",
      "246 out of 365\n",
      "247 out of 365\n",
      "248 out of 365\n",
      "249 out of 365\n",
      "250 out of 365\n",
      "251 out of 365\n",
      "252 out of 365\n",
      "253 out of 365\n",
      "254 out of 365\n",
      "255 out of 365\n",
      "256 out of 365\n",
      "257 out of 365\n",
      "258 out of 365\n",
      "259 out of 365\n",
      "260 out of 365\n",
      "261 out of 365\n",
      "262 out of 365\n",
      "263 out of 365\n",
      "264 out of 365\n",
      "265 out of 365\n",
      "266 out of 365\n",
      "267 out of 365\n",
      "268 out of 365\n",
      "269 out of 365\n",
      "270 out of 365\n",
      "271 out of 365\n",
      "272 out of 365\n",
      "273 out of 365\n",
      "274 out of 365\n",
      "275 out of 365\n",
      "276 out of 365\n",
      "277 out of 365\n",
      "278 out of 365\n",
      "279 out of 365\n",
      "280 out of 365\n",
      "281 out of 365\n",
      "282 out of 365\n",
      "283 out of 365\n",
      "284 out of 365\n",
      "285 out of 365\n",
      "286 out of 365\n",
      "287 out of 365\n",
      "288 out of 365\n",
      "289 out of 365\n",
      "290 out of 365\n",
      "291 out of 365\n",
      "292 out of 365\n",
      "293 out of 365\n",
      "294 out of 365\n",
      "295 out of 365\n",
      "296 out of 365\n",
      "297 out of 365\n",
      "298 out of 365\n",
      "299 out of 365\n",
      "300 out of 365\n",
      "301 out of 365\n",
      "302 out of 365\n",
      "303 out of 365\n",
      "304 out of 365\n",
      "305 out of 365\n",
      "306 out of 365\n",
      "307 out of 365\n",
      "308 out of 365\n",
      "309 out of 365\n",
      "310 out of 365\n",
      "311 out of 365\n",
      "312 out of 365\n",
      "313 out of 365\n",
      "314 out of 365\n",
      "315 out of 365\n",
      "316 out of 365\n",
      "317 out of 365\n",
      "318 out of 365\n",
      "319 out of 365\n",
      "320 out of 365\n",
      "321 out of 365\n",
      "322 out of 365\n",
      "323 out of 365\n",
      "324 out of 365\n",
      "325 out of 365\n",
      "326 out of 365\n",
      "327 out of 365\n",
      "328 out of 365\n",
      "329 out of 365\n",
      "330 out of 365\n",
      "331 out of 365\n",
      "332 out of 365\n",
      "333 out of 365\n",
      "334 out of 365\n",
      "335 out of 365\n",
      "336 out of 365\n",
      "337 out of 365\n",
      "338 out of 365\n",
      "339 out of 365\n",
      "340 out of 365\n",
      "341 out of 365\n",
      "342 out of 365\n",
      "343 out of 365\n",
      "344 out of 365\n",
      "345 out of 365\n",
      "346 out of 365\n",
      "347 out of 365\n",
      "348 out of 365\n",
      "349 out of 365\n",
      "350 out of 365\n",
      "351 out of 365\n",
      "352 out of 365\n",
      "353 out of 365\n",
      "354 out of 365\n",
      "355 out of 365\n",
      "356 out of 365\n",
      "357 out of 365\n",
      "358 out of 365\n",
      "359 out of 365\n",
      "360 out of 365\n",
      "361 out of 365\n",
      "362 out of 365\n",
      "363 out of 365\n",
      "364 out of 365\n"
     ]
    }
   ],
   "source": [
    "#creating sliced and padded data = audio_data\n",
    "audio_data=[]\n",
    "for idx, sample in enumerate(cycle_list):\n",
    "            print(str(idx)+\" out of \"+str(len(cycle_list)))\n",
    "            output = split_and_pad(sample, desired_length, sample_rate, types=1)\n",
    "            audio_data.extend(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e175bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device_wise_list\n",
    "file_to_device = {}\n",
    "device_to_id = {}\n",
    "device_id = 0\n",
    "files = audio_train['Filename']#os.listdir(data_dir)\n",
    "device_patient_list = []\n",
    "pats = []\n",
    "for f in files:\n",
    "    device = f.strip().split('_')[-1].split('.')[0]\n",
    "    if device not in device_to_id:\n",
    "        device_to_id[device] = device_id\n",
    "        device_id += 1\n",
    "        device_patient_list.append([])\n",
    "    file_to_device[f.strip().split('.')[0]] = device_to_id[device]\n",
    "    pat = f.strip().split('_')[0]\n",
    "    if pat not in device_patient_list[device_to_id[device]]:\n",
    "        device_patient_list[device_to_id[device]].append(pat)\n",
    "    if pat not in pats:\n",
    "        pats.append(pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c56c33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating labels for sliced and paddedd data = audio_data\n",
    "class_probs=np.zeros(4)\n",
    "identifiers=[]\n",
    "device_wise=[]\n",
    "labels=[]\n",
    "for idx in range(device_id):\n",
    "            device_wise.append([])\n",
    "for idx, sample in enumerate(audio_data):\n",
    "            class_probs[sample[1]] += 1.0\n",
    "            labels.append(sample[1])\n",
    "            identifiers.append(sample[2]+'_'+str(sample[3])+'_'+str(sample[1]))\n",
    "            device_wise[file_to_device[sample[2]]].append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dbf6fd",
   "metadata": {},
   "source": [
    "<b>audio_data</b> is the data which padded and augmented (in the simple way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c65aa6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating mel spectrograms from augmented and padded data\n",
    "def create_mel_raw(current_window, sample_rate, n_mels=128, f_min=50, f_max=4000, nfft=2048, hop=512, resz=1):\n",
    "    S = librosa.feature.melspectrogram(y=current_window, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max, n_fft=nfft, hop_length=hop)\n",
    "    S = librosa.power_to_db(S, ref=np.max)\n",
    "    S = (S-S.min()) / (S.max() - S.min())\n",
    "    S *= 255\n",
    "    img = cv2.applyColorMap(S.astype(np.uint8), cmapy.cmap('magma'))\n",
    "    height, width, _ = img.shape\n",
    "    if resz > 0:\n",
    "        img = cv2.resize(img, (width*resz, height*resz), interpolation=cv2.INTER_LINEAR)\n",
    "    img = cv2.flip(img, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b309867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=[]\n",
    "for index in range(len(audio_data)):\n",
    "    audio=audio_data[index][0]\n",
    "    # convert audio signal to spectrogram\n",
    "    # spectrograms resized to 3x of original size\n",
    "    audio_image = cv2.cvtColor(create_mel_raw(audio, sample_rate, f_max=f_max, \n",
    "            n_mels=n_mels, nfft=nfft, hop=hop, resz=3), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # blank region clipping\n",
    "    audio_raw_gray = cv2.cvtColor(create_mel_raw(audio, sample_rate, f_max=f_max, \n",
    "            n_mels=n_mels, nfft=nfft, hop=hop), cv2.COLOR_BGR2GRAY)\n",
    "    audio_raw_gray[audio_raw_gray < 10] = 0\n",
    "    for row in range(audio_raw_gray.shape[0]):\n",
    "        black_percent = len(np.where(audio_raw_gray[row,:]==0)[0])/len(audio_raw_gray[row,:])\n",
    "        if black_percent < 0.80:\n",
    "            break   \n",
    "    if (row+1)*3 < audio_image.shape[0]:\n",
    "        audio_image = audio_image[(row+1)*3:, :, :]\n",
    "    audio_image = cv2.resize(audio_image, (audio_image.shape[1], n_mels*3), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "    \n",
    "    label = audio_data[index][1]\n",
    "    train_dataset.append((audio_image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c95630c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 753, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e55ad9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "for i in range(len(train_dataset)):\n",
    "    X_train.append(train_dataset[i][0])\n",
    "    y_train.append(train_dataset[i][1])  \n",
    "#display(X_train)\n",
    "np.save('X_train_temp', np.concatenate(X_train, axis=0).reshape(365, 192, 753, 3))\n",
    "np.save('y_train_temp', y_train)\n",
    "\n",
    "# print(\"X_train length : \"+str(len(X_train)))\n",
    "# print(\"X_train sample length : \"+str(X_train[0].shape))\n",
    "# print(\"Array : \"+str(np.concatenate(X_train, axis=0).shape))\n",
    "\n",
    "# np.concatenate(X_train, axis=0).reshape(365, 192, 753, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f91ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
